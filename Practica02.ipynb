{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccf9884",
   "metadata": {},
   "source": [
    "# Preparación de datos con Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f442b51",
   "metadata": {},
   "source": [
    "Autores: Ismael Sagredo Olivenza y Fernando Carlos López Hernández"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11703f9",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c297625",
   "metadata": {},
   "source": [
    "Pandas es el acrónimo de (Python Data Analysis Library) es un código fuente open source con licencia BSD que proporciona estructuras de datos, herramientas de análisis en python, fáciles de usar y de alto rendimiento.\n",
    "\n",
    "**Dataframe**\n",
    "\n",
    "Es la estuctura fundamental de Pandas. Es una especie de tabla que permite cargar información proveniente de un fichero y poder manejarla a nuestro antojo. Soporta importación directa desde csv lo que es muy útil ya que es el formato más extendido de los diferentes datasets que están publicados en internet.\n",
    "El dataframe puede tener en cada columna un tipo de datos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94476dc",
   "metadata": {},
   "source": [
    "Vamos a trabajar con Python para tener cierta soltura con el lenguaje antes realizar los laboratorios.\n",
    "Para ello vamos a realizar el siguiente ejercicios que consisten en trabajar con el datase de películas de movielens dataset que se puede descargar aquí:\n",
    "https://grouplens.org/datasets/movielens/\n",
    "\n",
    "Lo primero que haremos será cargar el fichero movies_metadata.csv usando Pandas en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ded621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deiviss\\AppData\\Local\\Temp\\ipykernel_12724\\3919483189.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies = pd.read_csv('movies_metadata.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "\n",
       "     original_title                                           overview  ...  \\\n",
       "0         Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1           Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
       "2  Grumpier Old Men  A family wedding reignites the ancient feud be...  ...   \n",
       "\n",
       "  release_date      revenue runtime  \\\n",
       "0   1995-10-30  373554033.0    81.0   \n",
       "1   1995-12-15  262797249.0   104.0   \n",
       "2   1995-12-22          0.0   101.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "2           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "                                             tagline             title  video  \\\n",
       "0                                                NaN         Toy Story  False   \n",
       "1          Roll the dice and unleash the excitement!           Jumanji  False   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...  Grumpier Old Men  False   \n",
       "\n",
       "  vote_average vote_count  \n",
       "0          7.7     5415.0  \n",
       "1          6.9     2413.0  \n",
       "2          6.5       92.0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "movies = pd.read_csv('movies_metadata.csv')\n",
    "\n",
    "movies.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1e65a",
   "metadata": {},
   "source": [
    "El warning se produce porque hay algunos campos del dataset que son multicampo y no sabe de que tipo son. Vamos a establecer los tipos para que desaparezca el warning. Como nos indica que el campo que no conoce es el 10, establecemos el 10 como str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b680ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies = pd.read_csv('movies_metadata.csv',dtype={ 10 : 'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1fd97",
   "metadata": {},
   "source": [
    "Podemos visualizar el dataframe entero usando display. Pero en muchas ocasiones nos interesa mostrar solo una parte del dataframe para que podamos ver que pinta tiene el dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(movies.head(n=4));\n",
    "display(movies.tail(n=4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e36b9e",
   "metadata": {},
   "source": [
    "Echamos un vistazo al dataframe, los principales campos que nos interesan son el id, el original_title, los géneros, pero también hay otros interesantes como el rating medio vote_ average.\n",
    "\n",
    "Ahora cargamos el fichero de ratings ratings_small.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20395893",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ratings.head(n=4));\n",
    "display(ratings.tail(n=4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5d51d",
   "metadata": {},
   "source": [
    "En el fichero rating tenemos las valoraciones de los usuarios identificados con un id anónimo (userId) y el identificador de la palícula (movieId). De esta forma podemos relacionar ambos dataframes. Por ejemplo, si queremos buscar todas las votaciones de una película concreta podemos extraer el id de la película que queremos buscar y con ese id consultar los ratings. Buscamos por ejemplo la película \"The Lation King\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lion = movies[movies[\"title\"] == \"The Lion King\"]\n",
    "display(lion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ccb02f",
   "metadata": {},
   "source": [
    "Pero buscar en un campo de texto de esta forma es complicado, ya que podemos estar buscando un texto y este no estar escrito exactamente igual que el almacenado (puedes poner una letra minúscula en alguna de las mayúsculas para comprobarlo). Una solución es buscar parcialmente. Pandas no lo permite hacer directamente, pero tenemos algunos trucos para conseguirlo, por ejemplo usando máscaras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = 'lion king'\n",
    "#Hacemos una subselección de los dos campos que nos interesan y los copiamos a otro dataframe\n",
    "titles=movies[[\"original_title\",\"id\"]].copy();\n",
    "# Nos creamos una máscara con el método applymap que nos indica que campos contienen una condición que establecemos mediante una lambda\n",
    "mask = titles.applymap(lambda x:  tested.lower() in str(x).lower())\n",
    "# Aplicamos la mascara para encontrar que campos nos interesan usando la función any\n",
    "df1 = titles[mask.any(axis=1)]\n",
    "#Any nos devuelve la fila o columna (dependiendo del axis) que al menos tenga un campo a true de la máscara. Axis 1 indica\n",
    "# la columna en este caso. Si queremos devolver la fila, sería axis = 0\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8d1fe0",
   "metadata": {},
   "source": [
    "Nos encuentra tres de las películas de de la saga de The Lion King. Ahora podemos identificar correctamente el criterio de búisqueda para seleccionar correctamente el que deseamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9043db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lion = movies[movies[\"title\"] == \"The Lion King\"]\n",
    "display(lion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1a5df",
   "metadata": {},
   "source": [
    "Identificada la entrada de la película que queremos buscar, ahora procedemos, usando el ID a buscar los ratings de dicha película. Para acceder al valor del id tenemos que usar la función loc que define una selección a traves de un indice, en nuestro caso el 0 que nos devolverá la fila del índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lionId = int(lion[\"id\"].loc[lion.index[0]])\n",
    "#lionId = movies[movies[\"title\"] == \"The Lion King\"][\"id\"]\n",
    "print(lionId)\n",
    "ratingLion = ratings[ratings[\"movieId\"] == lionId]\n",
    "display(ratingLion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8acec",
   "metadata": {},
   "source": [
    "Ahora queremos calcular la media de las valoraciones de la película en el fichero de ratings. Para ello vamos a ejecutar la función mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratingLion[\"rating\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d0fba",
   "metadata": {},
   "source": [
    "Entre los campos vemos que hay un timestamp, vamos a convertirlo a date y le cambiamos el nombre a la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfeb4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "ratings[\"timestamp\"] = ratings[\"timestamp\"].apply(lambda x:  datetime.datetime.fromtimestamp(x).isoformat())\n",
    "ratings.rename(columns = {'timestamp':'datetime'}, inplace = True)\n",
    "display(ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d8514",
   "metadata": {},
   "source": [
    "vamos a extraer el género de la película, lo primero que vemos es que los nombres estan con comillas simples, esto provoca un error en el parseo de json, asi que debemos primero limpiar la info usando replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f2a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = lion[\"genres\"].loc[lion.index[0]];\n",
    "genre = genre.replace(\"'\", \"\\\"\")\n",
    "import json\n",
    "genreArray = json.loads(genre)\n",
    "for g in genreArray:\n",
    "    print(g[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8a060",
   "metadata": {},
   "source": [
    "Ahora vamos a aplicar una función que convierta los géneros en una cadena separada por comas para poder usarla en nuestras consultas más cómodamente. Para ello vamos a usar la función apply que nos permite aplicar una función a una fila o columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_genre(x):\n",
    "    x = x.replace(\"'\", \"\\\"\")\n",
    "    xArr = json.loads(x)\n",
    "    strOut = \"\"\n",
    "    for g in xArr:\n",
    "        strOut = strOut + g[\"name\"] + \",\"\n",
    "    strOut = strOut[0:-1]\n",
    "    return strOut\n",
    "\n",
    "\n",
    "movies[\"genres\"] = movies[\"genres\"].apply(transform_genre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13a9a2",
   "metadata": {},
   "source": [
    "Ahora podemos buscar todas las películas de animación y por ejemplo calcular su puntuación media usando una máscara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = \"Animation\"\n",
    "maskGenre = movies.applymap(lambda x:  tested.lower() in str(x).lower())\n",
    "animation = movies[maskGenre.any(axis=1)]\n",
    "display(animation.head())\n",
    "print(animation[\"vote_average\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc895ab9",
   "metadata": {},
   "source": [
    "Ahora vamos a contar aquellas películas que tenían video y ver si son más que las que no lo tienen, para ello usamos groupby. Esta función agrupa por uno o varios campos, haciendo una especie de lista de colisiones para el resto de campos, de forma que podemos luego hacer preguntas sobre la lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7dfac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numVideo = movies.groupby(\"video\").count()\n",
    "display(numVideo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9b87a",
   "metadata": {},
   "source": [
    "Como vemos, la función count se aplica a todos los campos de la lista de colisión. Pero podemos aplicarlo a un campo concreto, al que nos interese, para que sea más óptimo. Por ejemplo vamos a calcular el runtime medio de las películas de video y las que no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96541f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenueVideo = movies.groupby(\"video\")[\"runtime\"].mean()\n",
    "print(revenueVideo[revenueVideo.index[0]])\n",
    "print(revenueVideo[revenueVideo.index[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbcde05",
   "metadata": {},
   "source": [
    "Cargamos el fichero credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7487bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv('credits.csv')\n",
    "display(credits.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe2c65",
   "metadata": {},
   "source": [
    "Y hacemos un merge entre movies y credits por el campo id. Si el campo id es int64 convertirlo a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f851b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"id\"] = movies[\"id\"].astype(str)\n",
    "credits[\"id\"] = credits[\"id\"].astype(str)\n",
    "movie_credits = pd.merge(movies,credits,how='inner',on=('id'))\n",
    "display(movie_credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fab295",
   "metadata": {},
   "source": [
    "Ahora podemos saber los actores de una película, pero tambien que películas ha hecho un actor.\n",
    "## Ejercicio 01\n",
    "Buscar todas las películas interpretadas por **Bruce Willis**. Pero nos vamos a encontrar nuevamente con problemas en el json. Hay dos estrategias posibles, limpiar el json o ir al grano. Limpiar el json será costoso y dará bastantes problemas os proponemos la segunda opción:\n",
    "Hay que crear una función que convierta Json a array por espacios. La función anterior no nos vale porque este json tiene errores que hay que subsanar más allá de convertir comillas simples por dobles (por ejemplo algunos campos tiene comillas simples en el interior del campo), por lo que es mejor ir directamente a procesar los campos name: <nombre del actor> extraerlos y contruir una lista sin usar el parser de json.\n",
    "    \n",
    "NOTA: Esto es muy típico en los datasets, no todos los datos vienen limpios y gran parte del trabajo en IA en general y Machine Learning en particular es preprocesar los datos paraque nos sean útiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b529a55a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m credits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m credits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(ast\u001b[38;5;241m.\u001b[39mliteral_eval)\n\u001b[0;32m      7\u001b[0m credits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautor_list\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m credits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcast\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [actor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m actor \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m----> 8\u001b[0m credits_willis \u001b[38;5;241m=\u001b[39m \u001b[43mcredits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcredits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mautor_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mactor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBruce Willis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mactor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m credits_willis\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6195\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6192\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(keyarr)\n\u001b[0;32m   6194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 6195\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6196\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex(keyarr)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6182\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6165\u001b[0m \u001b[38;5;124;03mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[0;32m   6166\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6179\u001b[0m \u001b[38;5;124;03marray([0, 2])\u001b[39;00m\n\u001b[0;32m   6180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 6182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6183\u001b[0m indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n\u001b[0;32m   6184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3953\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3948\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m this\u001b[38;5;241m.\u001b[39m_get_indexer(\n\u001b[0;32m   3950\u001b[0m         target, method\u001b[38;5;241m=\u001b[39mmethod, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m   3951\u001b[0m     )\n\u001b[1;32m-> 3953\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3980\u001b[0m, in \u001b[0;36mIndex._get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3978\u001b[0m         tgt_values \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39m_get_engine_target()\n\u001b[1;32m-> 3980\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer)\n",
      "File \u001b[1;32mindex.pyx:351\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7132\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Escribe aqui el ejercicio 1\n",
    "import pandas as pd \n",
    "import ast\n",
    "\n",
    "credits = pd.read_csv(\"credits.csv\")\n",
    "credits[\"cast\"] = credits[\"cast\"].apply(ast.literal_eval)\n",
    "credits[\"autor_list\"] = credits['cast'].apply(lambda x: [actor['name'] for actor in x])\n",
    "credits_willis = credits[credits['autor_list'].apply(lambda x: [actor == \"Bruce Willis\" for actor in x])]\n",
    "credits_willis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf2ce3",
   "metadata": {},
   "source": [
    "Vamos a filtrar todas las películas de animación que tienen homepage y vamos a crearnos un dataframe manualmente con tres columnas, el id de la película, el título y el homepage y generaremos un número aleatorio . Después, escribiremos el dataframe como csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7be4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimationHomepage = animation[animation[\"homepage\"].notnull()]\n",
    "display(AnimationHomepage)\n",
    "NewAnimationHomepage = pd.DataFrame({'id':AnimationHomepage['id'],\n",
    "                          'homepage':AnimationHomepage[\"homepage\"],\n",
    "                          'title':AnimationHomepage[\"title\"]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f68d3a",
   "metadata": {},
   "source": [
    "Escribimos el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8609fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewAnimationHomepage.to_csv(\"NewAnimationHomepage.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ec95a9",
   "metadata": {},
   "source": [
    "## Uso de sklearn para calcular una regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3b827",
   "metadata": {},
   "source": [
    "Sklearn es la libreria principal que vamos a utilizar para aplicar técnicas\n",
    "de aprendizaje máquina. Pero despone de multitud de herramientas que son útiles\n",
    "Por ejemplo dispone de regresión lineal.\n",
    "\n",
    "Vamos a optener la ecuación lineal que minimiza el error cuadrático medio.\n",
    "Esta ecuación constará de una variable dependiente y un conjunto de variables\n",
    "independientes.\n",
    "\n",
    "Para cada x se optendrá un error concreto en función de la distancia existente\n",
    "entre el punto marcado por la recta y el valor real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a471e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#cargando el dataset de diabetes que incorpora sklearn.\n",
    "diabetes = datasets.load_diabetes()\n",
    "#usamos solo una caracteristica\n",
    "diabetes_x = diabetes.data[:,np.newaxis,2]\n",
    "#dividimos el dato ente entrenamiento y validación o test.\n",
    "#esto es algo recurrente cuando hacemos aprendizaje máquina.\n",
    "\n",
    "diabetes_x_train = diabetes_x[:-20] # Todos menos los 20 ultimos.\n",
    "\n",
    "diabetes_x_test = diabetes_x[-20:] # desde el puesto 10 empezanod por le final hasta el final\n",
    "\n",
    "# luego cogemos las clases para obtener los valores esperados.\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "#creamos la regresión lineal:\n",
    "linearreg = linear_model.LinearRegression()\n",
    "linearreg.fit(diabetes_x_train, diabetes_y_train)\n",
    "\n",
    "#Comprobamos la capacidad de predicción\n",
    "diabetes_y_pred = linearreg.predict(diabetes_x_test)\n",
    "print(\"Mostramos los valores obtenidos por la regresión lineal\")\n",
    "print('Coeficientes: \\n', linearreg.coef_)\n",
    "print(\"MSE: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "print('R2: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred)) #coeficiente de regresión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576cb5a3",
   "metadata": {},
   "source": [
    "Ahora dibujamos una gráfica usando matplotlib.pyplot que muestre la matriz de puntos y al recta de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(diabetes_x_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_x_test, diabetes_y_pred, color='blue', linewidth=3) #en linewidth le indicamos la linea en la gráfica.\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b197f7",
   "metadata": {},
   "source": [
    "# Ejercicio 02\n",
    "Realiza otra recta de regresión del dataset \"Boston\" (Boston house prices) que tambien podeis encontrar en sklearn, pintando su gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aqui el ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed114b16",
   "metadata": {},
   "source": [
    "# Ejercicio 03\n",
    "Basándote en datos aleatorios (los que quieras) crea un gráfico de tarta (pie chart) con Mapplotlib. La gráfica debe tener un título, etiquetas de cada clase, visible los porcentajes de cada clase y opcionalmente una de las clases resaltadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aqui el ejercicio 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
