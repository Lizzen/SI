{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750f074c",
   "metadata": {},
   "source": [
    "# Examen de Sistemas Inteligentes 2024\n",
    "## Parte práctica\n",
    "### Nombre del alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2e9c8",
   "metadata": {},
   "source": [
    "Pon aquí tu nombre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8035d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f502b7",
   "metadata": {},
   "source": [
    "**Instrucciones:** Carga el fichero mushroom.csv, y contexta las preguntas debajo de los encabezados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed289b0",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef56b2",
   "metadata": {},
   "source": [
    "Es una red neuronal CNN o NN las cuales son muy buenas para procesar imagenes y convertirlas en datos. Esta red tiene una red de entrada de 128x128*3 y una salida de 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41a5ed",
   "metadata": {},
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "95cc1f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap-diameter       2\n",
      "cap-shape          0\n",
      "gill-attachment    0\n",
      "gill-color         0\n",
      "stem-height        0\n",
      "stem-width         2\n",
      "stem-color         0\n",
      "season             0\n",
      "class              0\n",
      "dtype: int64\n",
      "cap-diameter       0\n",
      "cap-shape          0\n",
      "gill-attachment    0\n",
      "gill-color         0\n",
      "stem-height        0\n",
      "stem-width         0\n",
      "stem-color         0\n",
      "season             0\n",
      "class              0\n",
      "dtype: int64\n",
      "(54031, 4)\n",
      "(54031,)\n",
      "(54031, 43)\n",
      "(43224, 43)\n",
      "(10807, 43)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"./mushroom.csv\")\n",
    "\n",
    "# contar nan y drop\n",
    "print(df.isna().sum())\n",
    "df = df.dropna(how=\"any\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "cap = df[\"cap-shape\"].to_numpy()\n",
    "df = df.drop(\"cap-shape\",axis=1)\n",
    "gillA = df[\"gill-attachment\"].to_numpy()\n",
    "df = df.drop(\"gill-attachment\", axis=1)\n",
    "gillC = df[\"gill-color\"].to_numpy()\n",
    "df = df.drop(\"gill-color\", axis=1)\n",
    "stem = df[\"stem-color\"].to_numpy()\n",
    "df = df.drop(\"stem-color\", axis=1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "cap = encoder.fit_transform(cap.reshape(-1,1))\n",
    "gillA = encoder.fit_transform(gillA.reshape(-1,1))\n",
    "gillC = encoder.fit_transform(gillC.reshape(-1,1))\n",
    "stem = encoder.fit_transform(stem.reshape(-1,1))\n",
    "\n",
    "Y = df[\"class\"].to_numpy()\n",
    "X = df.drop(\"class\", axis=1)\n",
    "X = X.to_numpy()\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "X = np.hstack((X,cap, gillA, gillC, stem))\n",
    "print(X.shape)\n",
    "\n",
    "X_scaled = MinMaxScaler().fit_transform(X) #MinMaxScaler para salidas entre 0 y 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y\n",
    ")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7851b9f",
   "metadata": {},
   "source": [
    "### Ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4b26ba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53156240\n",
      "Iteration 2, loss = 0.35460511\n",
      "Iteration 3, loss = 0.26986067\n",
      "Iteration 4, loss = 0.22702673\n",
      "Iteration 5, loss = 0.20089382\n",
      "Iteration 6, loss = 0.18347089\n",
      "Iteration 7, loss = 0.16969942\n",
      "Iteration 8, loss = 0.15942851\n",
      "Iteration 9, loss = 0.15100268\n",
      "Iteration 10, loss = 0.14411385\n",
      "Iteration 11, loss = 0.13790338\n",
      "Iteration 12, loss = 0.13234865\n",
      "Iteration 13, loss = 0.12752368\n",
      "Iteration 14, loss = 0.12339938\n",
      "Iteration 15, loss = 0.11934330\n",
      "Iteration 16, loss = 0.11557098\n",
      "Iteration 17, loss = 0.11174224\n",
      "Iteration 18, loss = 0.10885997\n",
      "Iteration 19, loss = 0.10604489\n",
      "Iteration 20, loss = 0.10349953\n",
      "Iteration 21, loss = 0.10147952\n",
      "Iteration 22, loss = 0.09906517\n",
      "Iteration 23, loss = 0.09723775\n",
      "Iteration 24, loss = 0.09445968\n",
      "Iteration 25, loss = 0.09280279\n",
      "Iteration 26, loss = 0.09124778\n",
      "Iteration 27, loss = 0.08967889\n",
      "Iteration 28, loss = 0.08767881\n",
      "Iteration 29, loss = 0.08687940\n",
      "Iteration 30, loss = 0.08507307\n",
      "Iteration 31, loss = 0.08369525\n",
      "Iteration 32, loss = 0.08271843\n",
      "Iteration 33, loss = 0.08153202\n",
      "Iteration 34, loss = 0.08046994\n",
      "Iteration 35, loss = 0.07935959\n",
      "Iteration 36, loss = 0.07867939\n",
      "Iteration 37, loss = 0.07697492\n",
      "Iteration 38, loss = 0.07643037\n",
      "Iteration 39, loss = 0.07577208\n",
      "Iteration 40, loss = 0.07466204\n",
      "Iteration 41, loss = 0.07401254\n",
      "Iteration 42, loss = 0.07312533\n",
      "Iteration 43, loss = 0.07245943\n",
      "Iteration 44, loss = 0.07183473\n",
      "Iteration 45, loss = 0.07113233\n",
      "Iteration 46, loss = 0.07024670\n",
      "Iteration 47, loss = 0.07012619\n",
      "Iteration 48, loss = 0.06973424\n",
      "Iteration 49, loss = 0.06835855\n",
      "Iteration 50, loss = 0.06771539\n",
      "Iteration 51, loss = 0.06777010\n",
      "Iteration 52, loss = 0.06706213\n",
      "Iteration 53, loss = 0.06640812\n",
      "Iteration 54, loss = 0.06621164\n",
      "Iteration 55, loss = 0.06549658\n",
      "Iteration 56, loss = 0.06489042\n",
      "Iteration 57, loss = 0.06463181\n",
      "Iteration 58, loss = 0.06420481\n",
      "Iteration 59, loss = 0.06377224\n",
      "Iteration 60, loss = 0.06290495\n",
      "Iteration 61, loss = 0.06266038\n",
      "Iteration 62, loss = 0.06221384\n",
      "Iteration 63, loss = 0.06213087\n",
      "Iteration 64, loss = 0.06143129\n",
      "Iteration 65, loss = 0.06085879\n",
      "Iteration 66, loss = 0.06107695\n",
      "Iteration 67, loss = 0.06071162\n",
      "Iteration 68, loss = 0.06017574\n",
      "Iteration 69, loss = 0.05955945\n",
      "Iteration 70, loss = 0.05909622\n",
      "Iteration 71, loss = 0.05928443\n",
      "Iteration 72, loss = 0.05863188\n",
      "Iteration 73, loss = 0.05851182\n",
      "Iteration 74, loss = 0.05771505\n",
      "Iteration 75, loss = 0.05744406\n",
      "Iteration 76, loss = 0.05712806\n",
      "Iteration 77, loss = 0.05681649\n",
      "Iteration 78, loss = 0.05667690\n",
      "Iteration 79, loss = 0.05630537\n",
      "Iteration 80, loss = 0.05626191\n",
      "Iteration 81, loss = 0.05592199\n",
      "Iteration 82, loss = 0.05565283\n",
      "Iteration 83, loss = 0.05544956\n",
      "Iteration 84, loss = 0.05500530\n",
      "Iteration 85, loss = 0.05451254\n",
      "Iteration 86, loss = 0.05448654\n",
      "Iteration 87, loss = 0.05382662\n",
      "Iteration 88, loss = 0.05327397\n",
      "Iteration 89, loss = 0.05316583\n",
      "Iteration 90, loss = 0.05290305\n",
      "Iteration 91, loss = 0.05304909\n",
      "Iteration 92, loss = 0.05235113\n",
      "Iteration 93, loss = 0.05251146\n",
      "Iteration 94, loss = 0.05224411\n",
      "Iteration 95, loss = 0.05169637\n",
      "Iteration 96, loss = 0.05170183\n",
      "Iteration 97, loss = 0.05115927\n",
      "Iteration 98, loss = 0.05156619\n",
      "Iteration 99, loss = 0.05099805\n",
      "Iteration 100, loss = 0.05060714\n",
      "Iteration 101, loss = 0.05040747\n",
      "Iteration 102, loss = 0.05042548\n",
      "Iteration 103, loss = 0.05010849\n",
      "Iteration 104, loss = 0.04978933\n",
      "Iteration 105, loss = 0.04985695\n",
      "Iteration 106, loss = 0.04975823\n",
      "Iteration 107, loss = 0.04941704\n",
      "Iteration 108, loss = 0.04920110\n",
      "Iteration 109, loss = 0.04909355\n",
      "Iteration 110, loss = 0.04874920\n",
      "Iteration 111, loss = 0.04859401\n",
      "Iteration 112, loss = 0.04836072\n",
      "Iteration 113, loss = 0.04813641\n",
      "Iteration 114, loss = 0.04800079\n",
      "Iteration 115, loss = 0.04765582\n",
      "Iteration 116, loss = 0.04817894\n",
      "Iteration 117, loss = 0.04733011\n",
      "Iteration 118, loss = 0.04724065\n",
      "Iteration 119, loss = 0.04683656\n",
      "Iteration 120, loss = 0.04743516\n",
      "Iteration 121, loss = 0.04702782\n",
      "Iteration 122, loss = 0.04659213\n",
      "Iteration 123, loss = 0.04672381\n",
      "Iteration 124, loss = 0.04649842\n",
      "Iteration 125, loss = 0.04608608\n",
      "Iteration 126, loss = 0.04613283\n",
      "Iteration 127, loss = 0.04603414\n",
      "Iteration 128, loss = 0.04546707\n",
      "Iteration 129, loss = 0.04545477\n",
      "Iteration 130, loss = 0.04551959\n",
      "Iteration 131, loss = 0.04572741\n",
      "Iteration 132, loss = 0.04546864\n",
      "Iteration 133, loss = 0.04542404\n",
      "Iteration 134, loss = 0.04512255\n",
      "Iteration 135, loss = 0.04503211\n",
      "Iteration 136, loss = 0.04452818\n",
      "Iteration 137, loss = 0.04483676\n",
      "Iteration 138, loss = 0.04419121\n",
      "Iteration 139, loss = 0.04437392\n",
      "Iteration 140, loss = 0.04441310\n",
      "Iteration 141, loss = 0.04432299\n",
      "Iteration 142, loss = 0.04391875\n",
      "Iteration 143, loss = 0.04391134\n",
      "Iteration 144, loss = 0.04361300\n",
      "Iteration 145, loss = 0.04360223\n",
      "Iteration 146, loss = 0.04320963\n",
      "Iteration 147, loss = 0.04364200\n",
      "Iteration 148, loss = 0.04351691\n",
      "Iteration 149, loss = 0.04321063\n",
      "Iteration 150, loss = 0.04341443\n",
      "Iteration 151, loss = 0.04265557\n",
      "Iteration 152, loss = 0.04318603\n",
      "Iteration 153, loss = 0.04268717\n",
      "Iteration 154, loss = 0.04282839\n",
      "Iteration 155, loss = 0.04234897\n",
      "Iteration 156, loss = 0.04232595\n",
      "Iteration 157, loss = 0.04216458\n",
      "Iteration 158, loss = 0.04276941\n",
      "Iteration 159, loss = 0.04201510\n",
      "Iteration 160, loss = 0.04212767\n",
      "Iteration 161, loss = 0.04192750\n",
      "Iteration 162, loss = 0.04153992\n",
      "Iteration 163, loss = 0.04160609\n",
      "Iteration 164, loss = 0.04180907\n",
      "Iteration 165, loss = 0.04139617\n",
      "Iteration 166, loss = 0.04119981\n",
      "Iteration 167, loss = 0.04169700\n",
      "Iteration 168, loss = 0.04100801\n",
      "Iteration 169, loss = 0.04041536\n",
      "Iteration 170, loss = 0.04103304\n",
      "Iteration 171, loss = 0.04085768\n",
      "Iteration 172, loss = 0.04014029\n",
      "Iteration 173, loss = 0.04020691\n",
      "Iteration 174, loss = 0.04059590\n",
      "Iteration 175, loss = 0.04001948\n",
      "Iteration 176, loss = 0.04043630\n",
      "Iteration 177, loss = 0.04039052\n",
      "Iteration 178, loss = 0.04019244\n",
      "Iteration 179, loss = 0.03964898\n",
      "Iteration 180, loss = 0.03979043\n",
      "Iteration 181, loss = 0.03991265\n",
      "Iteration 182, loss = 0.03986077\n",
      "Iteration 183, loss = 0.03949673\n",
      "Iteration 184, loss = 0.03953592\n",
      "Iteration 185, loss = 0.03905324\n",
      "Iteration 186, loss = 0.03923115\n",
      "Iteration 187, loss = 0.03897500\n",
      "Iteration 188, loss = 0.03901448\n",
      "Iteration 189, loss = 0.03929188\n",
      "Iteration 190, loss = 0.03877835\n",
      "Iteration 191, loss = 0.03883262\n",
      "Iteration 192, loss = 0.03885103\n",
      "Iteration 193, loss = 0.03902637\n",
      "Iteration 194, loss = 0.03860037\n",
      "Iteration 195, loss = 0.03824019\n",
      "Iteration 196, loss = 0.03843915\n",
      "Iteration 197, loss = 0.03826051\n",
      "Iteration 198, loss = 0.03839200\n",
      "Iteration 199, loss = 0.03797780\n",
      "Iteration 200, loss = 0.03791835\n",
      "Iteration 201, loss = 0.03816660\n",
      "Iteration 202, loss = 0.03774348\n",
      "Iteration 203, loss = 0.03812182\n",
      "Iteration 204, loss = 0.03769362\n",
      "Iteration 205, loss = 0.03771780\n",
      "Iteration 206, loss = 0.03743439\n",
      "Iteration 207, loss = 0.03732140\n",
      "Iteration 208, loss = 0.03782567\n",
      "Iteration 209, loss = 0.03729539\n",
      "Iteration 210, loss = 0.03741501\n",
      "Iteration 211, loss = 0.03718970\n",
      "Iteration 212, loss = 0.03755764\n",
      "Iteration 213, loss = 0.03768138\n",
      "Iteration 214, loss = 0.03722472\n",
      "Iteration 215, loss = 0.03694603\n",
      "Iteration 216, loss = 0.03676499\n",
      "Iteration 217, loss = 0.03735662\n",
      "Iteration 218, loss = 0.03683530\n",
      "Iteration 219, loss = 0.03673425\n",
      "Iteration 220, loss = 0.03630319\n",
      "Iteration 221, loss = 0.03685373\n",
      "Iteration 222, loss = 0.03649491\n",
      "Iteration 223, loss = 0.03650244\n",
      "Iteration 224, loss = 0.03626392\n",
      "Iteration 225, loss = 0.03601090\n",
      "Iteration 226, loss = 0.03660125\n",
      "Iteration 227, loss = 0.03609386\n",
      "Iteration 228, loss = 0.03604494\n",
      "Iteration 229, loss = 0.03685658\n",
      "Iteration 230, loss = 0.03598300\n",
      "Iteration 231, loss = 0.03629810\n",
      "Iteration 232, loss = 0.03595997\n",
      "Iteration 233, loss = 0.03589614\n",
      "Iteration 234, loss = 0.03610020\n",
      "Iteration 235, loss = 0.03556396\n",
      "Iteration 236, loss = 0.03611036\n",
      "Iteration 237, loss = 0.03523559\n",
      "Iteration 238, loss = 0.03589945\n",
      "Iteration 239, loss = 0.03555672\n",
      "Iteration 240, loss = 0.03560641\n",
      "Iteration 241, loss = 0.03502368\n",
      "Iteration 242, loss = 0.03583137\n",
      "Iteration 243, loss = 0.03524891\n",
      "Iteration 244, loss = 0.03523153\n",
      "Iteration 245, loss = 0.03513711\n",
      "Iteration 246, loss = 0.03538338\n",
      "Iteration 247, loss = 0.03507737\n",
      "Iteration 248, loss = 0.03508244\n",
      "Iteration 249, loss = 0.03484847\n",
      "Iteration 250, loss = 0.03505422\n",
      "Iteration 251, loss = 0.03534466\n",
      "Iteration 252, loss = 0.03513522\n",
      "Iteration 253, loss = 0.03448022\n",
      "Iteration 254, loss = 0.03478882\n",
      "Iteration 255, loss = 0.03478118\n",
      "Iteration 256, loss = 0.03459433\n",
      "Iteration 257, loss = 0.03455402\n",
      "Iteration 258, loss = 0.03433416\n",
      "Iteration 259, loss = 0.03512466\n",
      "Iteration 260, loss = 0.03471909\n",
      "Iteration 261, loss = 0.03439139\n",
      "Iteration 262, loss = 0.03477602\n",
      "Iteration 263, loss = 0.03473455\n",
      "Iteration 264, loss = 0.03521019\n",
      "Iteration 265, loss = 0.03494765\n",
      "Iteration 266, loss = 0.03450774\n",
      "Iteration 267, loss = 0.03454198\n",
      "Iteration 268, loss = 0.03422045\n",
      "Iteration 269, loss = 0.03391213\n",
      "Iteration 270, loss = 0.03371761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deiviss\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (270) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import time \n",
    "\n",
    "t_p = time.time()\n",
    "model_p = MLPClassifier(max_iter=270, verbose=1).fit(x_train, y_train)\n",
    "t_p = time.time() - t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "73e34234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 1 0]\n",
      "[0 1 0 ... 1 1 0]\n",
      "0.9851022485426113\n"
     ]
    }
   ],
   "source": [
    "y_pred_p = model_p.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred_p)\n",
    "acc_p = model_p.score(x_test, y_test)\n",
    "print(acc_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b133c",
   "metadata": {},
   "source": [
    "### Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "898a336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100,\n",
    "                                  random_state=42,\n",
    "                                  max_depth=30,\n",
    "                                  min_samples_split=2,\n",
    "                                  min_samples_leaf=1,\n",
    "                                  n_jobs=-1,\n",
    "                                  verbose=1\n",
    "                                  )\n",
    "\n",
    "t_init = time.time()\n",
    "rf_model.fit(x_train, y_train)\n",
    "t_rf = time.time() - t_init\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0ea4d120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 1 0]\n",
      "[0 1 0 ... 1 1 0]\n",
      "0.991301933931711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf_model.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred_rf)\n",
    "acc_rf = rf_model.score(x_test, y_test)\n",
    "print(acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08778588",
   "metadata": {},
   "source": [
    "### Ejercicio 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4bec1bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron: 0.9851 Time: 35.67\n",
      "Random Forest: 0.9913 Time: 0.57\n",
      "                       Pred 0 (comestible)  Pred 1 (venenoso)\n",
      "Actual 0 (comestible)                 4790                 82\n",
      "Actual 1 (venenoso)                     79               5856\n",
      "                       Pred 0 (comestible)  Pred 1 (venenoso)\n",
      "Actual 0 (comestible)                 4822                 50\n",
      "Actual 1 (venenoso)                     44               5891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(f\"Perceptron: {acc_p:.4f} Time: {t_p:.2f}\")\n",
    "print(f\"Random Forest: {acc_rf:.4f} Time: {t_rf:.2f}\")\n",
    "\n",
    "def matrix_view(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    cm_df = pd.DataFrame(cm, index=['Actual 0 (comestible)', 'Actual 1 (venenoso)'],\n",
    "    columns=['Pred 0 (comestible)', 'Pred 1 (venenoso)'])\n",
    "    print(cm_df)\n",
    "\n",
    "matrix_view(y_test, y_pred_p)\n",
    "matrix_view(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262138e3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
