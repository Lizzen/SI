{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0tZ2iqWXjM_"
      },
      "source": [
        "# ***Imports***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uXho1GUXibE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, top_k_accuracy_score, accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzF4ozF0W9fl"
      },
      "source": [
        "# ***Limpieza de datos***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0iHMBw5W5_b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"./.csv\")\n",
        "dfTempHist = pd.read_excel('./.xls', header=x) #Donde x es el número de filas que quieres saltar\n",
        "# contar nan y drop\n",
        "countNaN = df.isna().sum()\n",
        "print(countNaN)\n",
        "df = df.dropna(how=\"any\")\n",
        "countNaN = df.isna().sum()\n",
        "print(countNaN)\n",
        "\n",
        "# Dropear valores menores que x(int)\n",
        "df = df.loc[df['colum'] >= x]\n",
        "# Definimos DataFrame para el posible Histograma\n",
        "df_Hist = df\n",
        "# Pasar a numpy y dropear las columnas no numéricas como colores, formas, tipos, etc. Los id no entran.\n",
        "cap = df[\"cap-shape\"].to_numpy()\n",
        "df = df.drop(\"cap-shape\",axis=1)\n",
        "gillA = df[\"gill-attachment\"].to_numpy()\n",
        "df = df.drop(\"gill-attachment\", axis=1)\n",
        "gillC = df[\"gill-color\"].to_numpy()\n",
        "df = df.drop(\"gill-color\", axis=1)\n",
        "stem = df[\"stem-color\"].to_numpy()\n",
        "df = df.drop(\"stem-color\", axis=1)\n",
        "\n",
        "# Codificar los datos no numericos\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "cap = encoder.fit_transform(cap.reshape(-1,1))\n",
        "gillA = encoder.fit_transform(gillA.reshape(-1,1))\n",
        "gillC = encoder.fit_transform(gillC.reshape(-1,1))\n",
        "stem = encoder.fit_transform(stem.reshape(-1,1))\n",
        "\n",
        "# Definimos Y: La variable de salida que define el problema\n",
        "Y = df[\"class\"].to_numpy()    # La pasamos a matriz numpy\n",
        "\n",
        "# Las demas columnas definen X, se necesita pasar a matriz numpy\n",
        "X = df.drop(\"class\", axis=1)\n",
        "X = X.to_numpy()\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "# Añadir los datos no numéricos a la matriz.\n",
        "X = np.hstack((X,cap, gillA, gillC, stem))\n",
        "print(X.shape)\n",
        "\n",
        "# Escalar X:\n",
        "#     MinMaxScaler: Valores 0/1 -> scaler = MinMaxScaler(feature_range=(2, 3)) 2/3\n",
        "#     StandarScaler: Rango de valores amplio\n",
        "X_scaled = MinMaxScaler().fit_transform(X) #MinMaxScaler para salidas entre 0 y 1\n",
        "\n",
        "# Entrenamiento: test_size es el % de test que pide el enunciado, en este caso 80/20%\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=Y\n",
        ")\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqlq7MFbY8O"
      },
      "source": [
        "# ***Histograma***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu6tzLOTabHd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_Hist.hist(bins=20, figsize=(12, 10))\n",
        "plt.suptitle('Distribución de todas las variables numéricas', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkMSbJ0UcMAJ"
      },
      "source": [
        "# ***Perceptron***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thqzuek7cQXG"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import time\n",
        "\n",
        "t_p = time.time()\n",
        "model_p = MLPClassifier(alpha=0.01, max_iter=3000, verbose=1, random_state=13).fit(x_train, y_train)\n",
        "t_p = time.time() - t_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPdocVvDcd4w"
      },
      "outputs": [],
      "source": [
        "y_pred_p = model_p.predict(x_test)\n",
        "print(y_test)\n",
        "print(y_pred_p)\n",
        "acc_p = model_p.score(x_test, y_test)\n",
        "print(acc_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlNviYSic4Du"
      },
      "source": [
        "# ***Segundo Algoritmo EJ: Random Forest***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUqKF3jDdBDV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100,\n",
        "                                  random_state=42,\n",
        "                                  max_depth=30,\n",
        "                                  min_samples_split=2,\n",
        "                                  min_samples_leaf=1,\n",
        "                                  n_jobs=-1,\n",
        "                                  verbose=1\n",
        "                                  )\n",
        "t_init = time.time()\n",
        "rf_model.fit(x_train, y_train)\n",
        "t_rf = time.time() - t_init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Zy4gF3idHlX"
      },
      "outputs": [],
      "source": [
        "y_pred_rf = rf_model.predict(x_test)\n",
        "print(y_test)\n",
        "print(y_pred_rf)\n",
        "acc_rf = rf_model.score(x_test, y_test)\n",
        "print(acc_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bliHOmVodeCe"
      },
      "source": [
        "# ***Ayuda a Explicacion***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCwW0CRaddjj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(f\"Perceptron: {acc_p:.4f} Time: {t_p:.2f}\")\n",
        "print(f\"Random Forest: {acc_rf:.4f} Time: {t_rf:.2f}\")\n",
        "\n",
        "def matrix_view(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Cambiar segun el problema\n",
        "    cm_df = pd.DataFrame(cm, index=['Actual 0 (comestible)', 'Actual 1 (venenoso)'],\n",
        "    columns=['Pred 0 (comestible)', 'Pred 1 (venenoso)'])\n",
        "    print(cm_df)\n",
        "\n",
        "matrix_view(y_test, y_pred_p)\n",
        "matrix_view(y_test, y_pred_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI7C2ynhd7yD"
      },
      "source": [
        "# ***SEGUN CHAT GPT!!!!!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKr9g4g5aPI-"
      },
      "outputs": [],
      "source": [
        "# Segun CHAT GPT!!!!!!!!\n",
        "import pandas as pd\n",
        "from ace_tools import display_dataframe_to_user\n",
        "\n",
        "# Cargar el dataset original\n",
        "df = pd.read_csv('/mnt/data/mushroom.csv')\n",
        "\n",
        "# Renombrar columnas para consistencia (opcional)\n",
        "df.rename(columns={\n",
        "    'cap-diameter': 'Cap Diameter',\n",
        "    'cap-shape': 'Cap Shape',\n",
        "    'gill-attachment': 'Gill Attachment',\n",
        "    'gill-color': 'Gill Color',\n",
        "    'stem-height': 'Stem Height',\n",
        "    'stem-width': 'Stem Width',\n",
        "    'stem-color': 'Stem Color',\n",
        "    'season': 'Season'\n",
        "}, inplace=True)\n",
        "\n",
        "# Mostrar las primeras filas para inspección inicial\n",
        "display_dataframe_to_user(\"Dataset Original - Primeras Filas\", df.head())\n",
        "\n",
        "# Identificar valores faltantes y posibles errores\n",
        "print(\"Valores nulos por columna:\\n\", df.isnull().sum())\n",
        "\n",
        "# Limpieza de errores:\n",
        "# 1. Reemplazar indicadores de valores erróneos ('?' o similares) por NaN\n",
        "df.replace('?', pd.NA, inplace=True)\n",
        "\n",
        "# 2. Eliminar filas con valores faltantes tras la sustitución\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Codificación de variables categóricas mediante one-hot encoding\n",
        "categorical_cols = ['Cap Shape', 'Gill Attachment', 'Gill Color', 'Stem Color']\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Asegurar que 'Season' y la clase objetivo estén en el tipo correcto\n",
        "df_encoded['Season'] = df_encoded['Season'].astype(float)\n",
        "df_encoded['class'] = df_encoded['class'].astype(int)\n",
        "\n",
        "# Mostrar las primeras filas del dataset limpio y formateado\n",
        "display_dataframe_to_user(\"Dataset Limpio y Formateado - Primeras Filas\", df_encoded.head())\n",
        "\n",
        "# Guardar el dataset limpio para uso posterior\n",
        "df_encoded.to_csv('/mnt/data/mushroom_clean.csv', index=False)\n",
        "\n",
        "df_encoded.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbLsq7VJd623"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from ace_tools import display_dataframe_to_user\n",
        "\n",
        "# Cargar el dataset limpio\n",
        "df = pd.read_csv('/mnt/data/mushroom_clean.csv')\n",
        "\n",
        "# Separar variables predictoras y objetivo\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Dividir en entrenamiento (80%) y prueba (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar multilayer perceptron\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "\n",
        "# Entrenar random forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "# Mostrar resultados\n",
        "results = pd.DataFrame({\n",
        "    'Modelo': ['Multilayer Perceptron', 'Random Forest'],\n",
        "    'Accuracy': [accuracy_mlp, accuracy_rf]\n",
        "})\n",
        "display_dataframe_to_user(\"Comparación de Accuracy\", results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
